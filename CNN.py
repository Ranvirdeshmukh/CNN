# -*- coding: utf-8 -*-
"""hw4-1-nn-pos-cim.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-K-ym4PfWt1ITSvR1S8E-LPLo1gwV_8a

# Examples for Homework 5.1: Neural Network for Cook Islands Māori Parts of Speech
Dartmouth College, LING48, Spring 2024<br>
Rolando Coto-Solano (Rolando.A.Coto.Solano@dartmouth.edu)

Code modified from:
https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/

You need to perform three tasks:

(a) Run the program three times and record the training and test accuracy for each of the three runs. What is the average training accuracy? What is the average accuracy for the test set? How are the F1-scores behaving? (You can see more information how the predictions are working by looking at the predictions for the first fifteen items).

(b)	Change the program so that the hidden layers have 48 and 24 neurons, and the output has 3 neurons. Run the modified program three times. What is the average training/test accuracy? How are the F1-scores behaving? (You can see more information how the predictions are working by looking at the predictions for the first ten items).

(c)	Use the same settings as you did in step ‘B’ above and make one more change: Change the program so that it runs for 200 epochs. Run this three times. What is the average training and test accuracy? How are the F1-scores behaving? (You can see more information how the predictions are working by looking at the predictions for the first ten items).

Write all of these answers in a PDF/Word/LibreOffice file. Include screeshots of your results.
"""

# load packages (neural network is in sklearn)
from numpy import loadtxt
import pandas as pd
from sklearn import preprocessing
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras import layers
import gdown
from keras.utils import to_categorical

import numpy as np
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

"""I recommend that you comment out to cell below and then go to<br>
"Runtime" > "Run all". This will automatically run everything,<br>
so you can just record the relevant data and run again and again.
"""

# Load file and split into training data (nX) and
# the labels we are trying to predict (ny)

cimData = pd.read_csv("cim-3pos.csv")
dataset = cimData
nX = cimData.drop('tokenPOS', axis=1)
ny = cimData['tokenPOS']

numberValidPOS = 3  # noun, verb, preposition

# Encode the words into numbers and then split
# the randomly data into training and test sets.

encoderX = preprocessing.OneHotEncoder(sparse_output=True)
X = encoderX.fit_transform(nX)

encoderY = preprocessing.LabelEncoder()
y = encoderY.fit_transform(ny)

y = to_categorical(y, num_classes=3)


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10)

inputDims = 1497 # the total of features in the OneHotEncoded X vector (total number of unique words)

# Here, you can study what the dataset looks like (as text and encoded)

print("--- Training data, predictive features, first row ---")
print(encoderX.inverse_transform(X_train[0:1]))
print("\n--- Training data, predicted result, first row ---")
print(encoderY.inverse_transform(np.argmax(y_train[0:1], axis=1)))
print("\n--- Training data, predictive features, first row, one-hot encoded ---")
print(X_train[0:1])
print("\n--- Training data, predicted result, first row, one-hot encoded ---")
print(y_train[0:1])

# define the keras model
model = Sequential()


model.add(Dense(48, input_dim=inputDims, activation='relu'))
# ***** CHANGE #3: Change second hidden layer from 6 to 24 neurons (remove redundant input_dim) *****
model.add(Dense(24, activation='relu'))
# ***** CHANGE #4: Change output layer from 1 neuron (with relu) to 3 neurons with softmax *****
model.add(Dense(3, activation='softmax'))

# ***** CHANGE #5: Compile with 'categorical_crossentropy' instead of 'binary_crossentropy' *****
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Fit the keras model on the dataset
model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)

# make class predictions with the model
print("===== Results from final layer of the first 5 items in test set =====")
preds_prob = model.predict(X_test)
print("1: " + str(preds_prob[0]))
print("2: " + str(preds_prob[1]))
print("3: " + str(preds_prob[2]))
print("4: " + str(preds_prob[3]))
print("5: " + str(preds_prob[4]))

# Efficiently convert predictions to class indices
predictions = np.argmax(preds_prob, axis=1)

# Convert true one-hot labels to integer labels for evaluation
true_labels = np.argmax(y_test, axis=1)

# Calculate accuracy
accuracy = round((np.sum(predictions == true_labels) / len(true_labels)) * 100, 0)
print("\n===== Size of test set =====")
print(len(true_labels))
print("\n===== Test data, predictive features, first 15 rows =====")
print(encoderX.inverse_transform(X_test[0:15]))
print("\n===== Test data, predicted result, first 15 rows =====")
print(predictions[0:15])
print("\n===== Test data, expected result, first 15 rows =====")
print(encoderY.inverse_transform(true_labels.reshape(-1, 1))[0:15])
print("\n===== Accuracy of test set =====")
print(str(accuracy) + "%")
print("\n===== Predictions =====")

for i in range(15):
    itemNum = "0" + str(i+1) if i < 9 else str(i+1)
    isItCorrect = "*Correct!*" if predictions[i] == true_labels[i] else ""
    print("item " + itemNum + ": Predicted: " + str(predictions[i]) + " /   " +
          str(encoderY.inverse_transform([predictions[i]])) + "  \tActual value: " +
          str(true_labels[i]) + " / " + str(encoderY.inverse_transform([true_labels[i]])) +
          " \t" + str(isItCorrect))

print("\n===== Classification Report =====")
print(classification_report(true_labels, predictions))
print("\n===== Confusion Matrix =====")
print(confusion_matrix(true_labels, predictions))